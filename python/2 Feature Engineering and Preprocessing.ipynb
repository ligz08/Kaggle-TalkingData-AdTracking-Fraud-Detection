{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Load\" data-toc-modified-id=\"Load-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load</a></span></li><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Feature Engineering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Datetime-features\" data-toc-modified-id=\"Datetime-features-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Datetime features</a></span></li><li><span><a href=\"#Click-&amp;-download-stats\" data-toc-modified-id=\"Click-&amp;-download-stats-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Click &amp; download stats</a></span></li></ul></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#One-hot-encode-categorical-features\" data-toc-modified-id=\"One-hot-encode-categorical-features-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>One-hot encode categorical features</a></span></li></ul></li><li><span><a href=\"#Save-data-objects\" data-toc-modified-id=\"Save-data-objects-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Save data objects</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import psycopg2\n",
    "\n",
    "# Programming tools\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "# Notebook options\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "use_train_sample = False\n",
    "train = pd.read_csv('../downloads/train_sample.csv') if use_train_sample else pd.read_csv('../downloads/train.csv')\n",
    "test = pd.read_csv('../downloads/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the large size of training data, my computer simply can't handle it. I am using a Postgres database to do the feature engineering tasks.\n",
    "\n",
    "The cells with Python codes originally written for feature engineering are turned to \"raw\" mode, so they won't be executed."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('train shape:', train.shape)\n",
    "print('test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sys.getsizeof(train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "train.drop(columns=['attributed_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two tables have been previously created in Postgres. They are named `train_raw` and `test_raw`, both under schema `talkingdata`, in database `kaggle`  \n",
    "Here's the list tables output from `psql` console:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "kaggle=# \\dt talkingdata.*\n",
    "             List of relations\n",
    "   Schema    |   Name    | Type  |  Owner   \n",
    "-------------+-----------+-------+----------\n",
    " talkingdata | test_raw  | table | postgres\n",
    " talkingdata | train_raw | table | postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data in CSV files were imported into Postgres database with `COPY` commands. ([Details about Postgres `COPY` command](http://www.postgresqltutorial.com/import-csv-file-into-posgresql-table/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_config import db_config\n",
    "conn = psycopg2.connect(**db_config)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE OR REPLACE VIEW {schema_name}.{out_table_name} AS\n",
      "SELECT\n",
      "    *,\n",
      "    DATE_PART('hour', click_time) AS click_hour,\n",
      "    DATE_PART('minute', click_time) AS click_minute,\n",
      "    DATE_PART('second', click_time) AS click_second,\n",
      "    DATE_PART('minute', click_time)::INTEGER % 15 AS click_minute_mod15,\n",
      "    DATE_PART('second', click_time)::INTEGER % 5 AS click_second_mod5\n",
      "FROM\n",
      "    {schema_name}.{in_table_name}\n",
      ";\n"
     ]
    }
   ],
   "source": [
    "with open('../sql/extend_datetime_features_template.sql', 'r') as f:\n",
    "    template = f.read()\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE OR REPLACE VIEW talkingdata.train_timedetails AS\n",
      "SELECT\n",
      "    *,\n",
      "    DATE_PART('hour', click_time) AS click_hour,\n",
      "    DATE_PART('minute', click_time) AS click_minute,\n",
      "    DATE_PART('second', click_time) AS click_second,\n",
      "    DATE_PART('minute', click_time)::INTEGER % 15 AS click_minute_mod15,\n",
      "    DATE_PART('second', click_time)::INTEGER % 5 AS click_second_mod5\n",
      "FROM\n",
      "    talkingdata.train_raw\n",
      ";\n",
      "CREATE OR REPLACE VIEW talkingdata.test_timedetails AS\n",
      "SELECT\n",
      "    *,\n",
      "    DATE_PART('hour', click_time) AS click_hour,\n",
      "    DATE_PART('minute', click_time) AS click_minute,\n",
      "    DATE_PART('second', click_time) AS click_second,\n",
      "    DATE_PART('minute', click_time)::INTEGER % 15 AS click_minute_mod15,\n",
      "    DATE_PART('second', click_time)::INTEGER % 5 AS click_second_mod5\n",
      "FROM\n",
      "    talkingdata.test_raw\n",
      ";\n"
     ]
    }
   ],
   "source": [
    "for dataset in ['train', 'test']:\n",
    "    query = template.format(schema_name='talkingdata', \n",
    "                            in_table_name=dataset+'_raw', \n",
    "                            out_table_name=dataset+'_timedetails')\n",
    "    print(query)\n",
    "    cur.execute(query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unused python pandas code"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def extend_datetime_features(df):\n",
    "    df['click_time'] = pd.to_datetime(df['click_time'])\n",
    "    df['click_hour'] = df['click_time'].dt.hour\n",
    "    df['click_minute'] = df['click_time'].dt.minute\n",
    "    df['click_second'] = df['click_time'].dt.second\n",
    "    df['click_minute_mod15'] = df['click_minute'] % 15\n",
    "    df['click_second_mod5'] = df['click_second'] % 5\n",
    "    return df\n",
    "\n",
    "train = extend_datetime_features(train)\n",
    "test = extend_datetime_features(test)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Click & download stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP VIEW IF EXISTS {schema_name}.{out_table_name};\n",
      "\n",
      "CREATE VIEW {schema_name}.{out_table_name} AS\n",
      "SELECT\n",
      "    {by_feature},\n",
      "    COUNT(*) AS clicks_by_{by_feature},\n",
      "    SUM(is_attributed) AS downloads_by_{by_feature},\n",
      "    SUM(is_attributed)::FLOAT / COUNT(*) AS download_ratio_by_{by_feature} \n",
      "FROM\n",
      "    {schema_name}.{in_table_name}\n",
      "GROUP BY\n",
      "    {by_feature}\n",
      ";\n"
     ]
    }
   ],
   "source": [
    "with open('../sql/get_stats_template.sql', 'r') as f:\n",
    "    template = f.read()\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create view: stats_by_ip\n",
      "Create view: stats_by_app\n",
      "Create view: stats_by_device\n",
      "Create view: stats_by_os\n",
      "Create view: stats_by_channel\n"
     ]
    }
   ],
   "source": [
    "for ft in ['ip', 'app', 'device', 'os', 'channel']:\n",
    "    query = template.format(schema_name='talkingdata', \n",
    "                            in_table_name='train_raw', \n",
    "                            out_table_name='stats_by_'+ft,\n",
    "                            by_feature=ft\n",
    "                           )\n",
    "#     print(query)\n",
    "    print('Create view:', 'stats_by_'+ft)\n",
    "    cur.execute(query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "source": [
    "%%time\n",
    "for ft in ['ip', 'app', 'device', 'os', 'channel']:\n",
    "    stats = train.groupby(ft).agg({'is_attributed': ['size', 'sum']})\n",
    "    stats.columns = stats.columns.droplevel(0)\n",
    "    cl_colname, dl_colname, ratio_colname = map(lambda col: col+'_by_'+ft, \n",
    "                                                ['clicks', 'downloads', 'download_ratio'])\n",
    "    stats.rename(columns={'size':cl_colname, 'sum':dl_colname}, inplace=True)\n",
    "    stats[ratio_colname] = stats[dl_colname] / stats[cl_colname]\n",
    "    \n",
    "    train = train.merge(stats, how='left', left_on=ft, right_index=True)\n",
    "    test = test.merge(stats, how='left', left_on=ft, right_index=True)\n",
    "    \n",
    "    del stats\n",
    "    gc.collect()\n",
    "\n",
    "train.fillna(0, inplace=True)\n",
    "test.fillna(0, inplace=True)\n",
    "gc.collect()\n",
    "\n",
    "print('train shape:', train.shape)\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(list(train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_cols = ['ip', 'app', 'device', 'os', 'channel', 'click_minute_mod15', 'click_second_mod5']\n",
    "num_cols = ['click_hour', 'click_minute', 'click_second', \n",
    "            'clicks_by_ip', 'downloads_by_ip', 'download_ratio_by_ip', \n",
    "            'clicks_by_app', 'downloads_by_app', 'download_ratio_by_app', \n",
    "            'clicks_by_device', 'downloads_by_device', 'download_ratio_by_device', \n",
    "            'clicks_by_os', 'downloads_by_os', 'download_ratio_by_os', \n",
    "            'clicks_by_channel', 'downloads_by_channel', 'download_ratio_by_channel']\n",
    "target_col = 'is_attributed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helper.plotting import plot_df_nunique\n",
    "plot_df_nunique(train, cat_cols, log_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[cat_cols].nunique().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_onehot = onehot_encoder.fit_transform(train[cat_cols])\n",
    "test_onehot = onehot_encoder.transform(test[cat_cols])\n",
    "\n",
    "print(train_onehot.shape)\n",
    "print(test_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = sparse.hstack((train[num_cols], train_onehot))\n",
    "y_train = train[target_col].values\n",
    "\n",
    "del train\n",
    "gc.collect()\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_test = sparse.hstack((test[num_cols], test_onehot))\n",
    "\n",
    "del test\n",
    "gc.collect()\n",
    "\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(type(X_train))\n",
    "display(type(y_train))\n",
    "display(type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sparse.save_npz('../scratch/X_train', X_train)\n",
    "np.save('../scratch/y_train', y_train)\n",
    "sparse.save_npz('../scratch/X_test', X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {
    "height": "281px",
    "left": "1497.03px",
    "right": "20px",
    "top": "106.5px",
    "width": "395px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
